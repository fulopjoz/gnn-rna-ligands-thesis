{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8705dfb0",
   "metadata": {
    "papermill": {
     "duration": 0.011939,
     "end_time": "2024-03-10T12:33:06.289066",
     "exception": false,
     "start_time": "2024-03-10T12:33:06.277127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GGNN Optuna Optimization\n",
    "This project demonstrates the use of a Gated Graph Neural Network (GGNN) model for a graph classification task. It includes the setup for GPU utilization, data loading and preparation, model definition, and the use of Optuna for hyperparameter optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04b413",
   "metadata": {
    "papermill": {
     "duration": 0.008023,
     "end_time": "2024-03-10T12:33:06.305901",
     "exception": false,
     "start_time": "2024-03-10T12:33:06.297878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Check GPU Availability\n",
    "This section checks the availability of a GPU for PyTorch, ensuring that model training can leverage hardware acceleration if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc62385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:06.350260Z",
     "iopub.status.busy": "2024-03-10T12:33:06.349847Z",
     "iopub.status.idle": "2024-03-10T12:33:06.357776Z",
     "shell.execute_reply": "2024-03-10T12:33:06.356230Z"
    },
    "papermill": {
     "duration": 0.046887,
     "end_time": "2024-03-10T12:33:06.360805",
     "exception": false,
     "start_time": "2024-03-10T12:33:06.313918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(\"PyTorch version:\", torch.__version__)\n",
    "# print(\"Is CUDA Supported?\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1f6501",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:06.462678Z",
     "iopub.status.busy": "2024-03-10T12:33:06.461983Z",
     "iopub.status.idle": "2024-03-10T12:33:06.468815Z",
     "shell.execute_reply": "2024-03-10T12:33:06.467029Z"
    },
    "papermill": {
     "duration": 0.034902,
     "end_time": "2024-03-10T12:33:06.471690",
     "exception": false,
     "start_time": "2024-03-10T12:33:06.436788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.cuda.is_available(), torch.cuda.device_count(), torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3e7ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:06.486425Z",
     "iopub.status.busy": "2024-03-10T12:33:06.485908Z",
     "iopub.status.idle": "2024-03-10T12:33:06.493372Z",
     "shell.execute_reply": "2024-03-10T12:33:06.491418Z"
    },
    "papermill": {
     "duration": 0.018565,
     "end_time": "2024-03-10T12:33:06.496480",
     "exception": false,
     "start_time": "2024-03-10T12:33:06.477915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# import dgl\n",
    "# import numpy as np\n",
    "# import optuna\n",
    "# from dgl.nn import GatedGraphConv, GlobalAttentionPooling\n",
    "# from dgl.dataloading import GraphDataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from optuna.visualization import plot_contour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af984e",
   "metadata": {
    "papermill": {
     "duration": 0.039097,
     "end_time": "2024-03-10T12:33:06.541556",
     "exception": false,
     "start_time": "2024-03-10T12:33:06.502459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading and Preparation\n",
    "Here, the data for training the GGNN model is loaded and prepared, including splitting into training, validation, and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd9068b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:06.556963Z",
     "iopub.status.busy": "2024-03-10T12:33:06.556426Z",
     "iopub.status.idle": "2024-03-10T12:33:06.563642Z",
     "shell.execute_reply": "2024-03-10T12:33:06.562080Z"
    },
    "papermill": {
     "duration": 0.018102,
     "end_time": "2024-03-10T12:33:06.566385",
     "exception": false,
     "start_time": "2024-03-10T12:33:06.548283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_trials = 2\n",
    "# num_epochs = 2\n",
    "\n",
    "# # Load data and prepare for training\n",
    "# reloaded_df = pd.read_csv(\"data_mvi/combined_df.csv\")\n",
    "# graphs, labels_dict = dgl.load_graphs(\"data_mvi/graphs.bin\")\n",
    "# labels = reloaded_df['binds_to_rna'].values\n",
    "\n",
    "# # Split dataset train, test\n",
    "# train_indices, test_indices, train_labels, test_labels = train_test_split(\n",
    "#     range(len(reloaded_df)), labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# # Split dataset train, validation\n",
    "# train_indices, val_indices, train_labels, val_labels = train_test_split(\n",
    "#     train_indices, train_labels, test_size=0.2, stratify=train_labels, random_state=42)\n",
    "\n",
    "# train_graphs = [graphs[i] for i in train_indices]\n",
    "# test_graphs = [graphs[i] for i in test_indices]\n",
    "# val_graphs = [graphs[i] for i in val_indices]\n",
    "\n",
    "# print(f'Train: {len(train_graphs)}, Validation: {len(val_graphs)}, Test: {len(test_graphs)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7cc8e",
   "metadata": {
    "papermill": {
     "duration": 0.006296,
     "end_time": "2024-03-10T12:33:06.579041",
     "exception": false,
     "start_time": "2024-03-10T12:33:06.572745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Model and Utilities\n",
    "This section defines the GGNN model, an early stopping utility to prevent overfitting, and a custom collate function for data loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdbbb465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:06.593387Z",
     "iopub.status.busy": "2024-03-10T12:33:06.592889Z",
     "iopub.status.idle": "2024-03-10T12:33:06.600544Z",
     "shell.execute_reply": "2024-03-10T12:33:06.598984Z"
    },
    "papermill": {
     "duration": 0.018941,
     "end_time": "2024-03-10T12:33:06.604003",
     "exception": false,
     "start_time": "2024-03-10T12:33:06.585062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class GraphClsGGNN(nn.Module):\n",
    "#     \"\"\"GGNN for graph classification\"\"\"\n",
    "#     def __init__(self, annotation_size, out_feats, n_steps, n_etypes, num_cls, dropout_rate=0.5):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#         annotation_size : int\n",
    "#             The input feature size\n",
    "#         out_feats : int\n",
    "#             The output feature size\n",
    "#         n_steps : int\n",
    "#             The number of propagation steps\n",
    "#         n_etypes : int\n",
    "#             The number of edge types\n",
    "#         num_cls : int\n",
    "#             The number of output classes\n",
    "#         dropout_rate : float\n",
    "#             The dropout rate\n",
    "#         \"\"\"\n",
    "#         super(GraphClsGGNN, self).__init__()\n",
    "#         self.dropout = nn.Dropout(dropout_rate)\n",
    "#         self.ggnn1 = GatedGraphConv(annotation_size, out_feats, n_steps, n_etypes)\n",
    "#         self.ggnn2 = GatedGraphConv(out_feats, out_feats, n_steps, n_etypes)\n",
    "#         self.pooling = GlobalAttentionPooling(nn.Linear(out_feats, 1))\n",
    "#         self.fc = nn.Linear(out_feats, num_cls)\n",
    "\n",
    "#     def forward(self, graph, feat):\n",
    "#         \"\"\"Forward pass\"\"\"\n",
    "#         h = F.relu(self.ggnn1(graph, feat))\n",
    "#         h = self.dropout(h)\n",
    "#         h = F.relu(self.ggnn2(graph, h))\n",
    "#         hg = self.pooling(graph, h)\n",
    "#         out = self.fc(hg)\n",
    "#         return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4f8b0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:07.024862Z",
     "iopub.status.busy": "2024-03-10T12:33:07.024194Z",
     "iopub.status.idle": "2024-03-10T12:33:07.033528Z",
     "shell.execute_reply": "2024-03-10T12:33:07.032103Z"
    },
    "papermill": {
     "duration": 0.425945,
     "end_time": "2024-03-10T12:33:07.036369",
     "exception": false,
     "start_time": "2024-03-10T12:33:06.610424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class EarlyStopping:\n",
    "#     \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "#     def __init__(self, patience=15, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "#         \"\"\" Initialize the EarlyStopping object \"\"\"\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             patience (int): How long to wait after last time validation loss improved.\n",
    "#                             Default: 15\n",
    "#             verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "#                             Default: False\n",
    "#             delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "#                             Default: 0\n",
    "#             path (str): Path for the checkpoint to be saved to.\n",
    "#                             Default: 'checkpoint.pt'\n",
    "#             trace_func (function): trace print function.\n",
    "#                             Default: print\n",
    "#         \"\"\"\n",
    "#         self.patience = patience\n",
    "#         self.verbose = verbose\n",
    "#         self.counter = 0\n",
    "#         self.best_score = None\n",
    "#         self.early_stop = False\n",
    "#         self.val_loss_min = np.Inf\n",
    "#         self.delta = delta\n",
    "#         self.path = path\n",
    "#         self.trace_func = trace_func\n",
    "\n",
    "#     def __call__(self, val_loss, model):\n",
    "#         \"\"\" Check if the validation loss has improved, and if not, increase the counter. \"\"\"\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             val_loss (float): The validation loss\n",
    "#             model (nn.Module): The model to be saved\n",
    "#         \"\"\"\n",
    "#         score = -val_loss\n",
    "#         if self.best_score is None:\n",
    "#             self.best_score = val_loss\n",
    "#             self.save_checkpoint(val_loss, model)\n",
    "#         elif val_loss > self.best_score - self.delta:\n",
    "#             self.counter += 1\n",
    "#             self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "#             if self.counter >= self.patience:\n",
    "#                 self.early_stop = True\n",
    "#         else:\n",
    "#             self.best_score = val_loss\n",
    "#             self.save_checkpoint(val_loss, model)\n",
    "#             self.counter = 0\n",
    "\n",
    "#     def save_checkpoint(self, val_loss, model):\n",
    "#         \"\"\" Saves model when validation loss decrease. \"\"\"\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             val_loss (float): The validation loss\n",
    "#             model (nn.Module): The model to be saved\n",
    "#         \"\"\"\n",
    "#         if self.verbose:\n",
    "#             self.trace_func(f'Saving model ...')\n",
    "#         torch.save(model.state_dict(), self.path)\n",
    "#         self.val_loss_min = val_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4167d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:07.055484Z",
     "iopub.status.busy": "2024-03-10T12:33:07.054938Z",
     "iopub.status.idle": "2024-03-10T12:33:07.061891Z",
     "shell.execute_reply": "2024-03-10T12:33:07.060408Z"
    },
    "papermill": {
     "duration": 0.022596,
     "end_time": "2024-03-10T12:33:07.065869",
     "exception": false,
     "start_time": "2024-03-10T12:33:07.043273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def collate(samples):\n",
    "#     \"\"\" Collate function for the DataLoader \"\"\"\n",
    "#     \"\"\"\n",
    "#     Args:\n",
    "#         samples (List): The list of samples\n",
    "#     \"\"\"\n",
    "#     graphs, labels = map(list, zip(*samples))\n",
    "#     batched_graph = dgl.batch(graphs)\n",
    "#     labels = torch.tensor(labels, dtype=torch.long)\n",
    "#     return batched_graph, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00faf28d",
   "metadata": {
    "papermill": {
     "duration": 0.009108,
     "end_time": "2024-03-10T12:33:07.084418",
     "exception": false,
     "start_time": "2024-03-10T12:33:07.075310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and Evaluation Pipeline\n",
    "Outlines the process for training the GGNN model, including the training loop, validation checks, and early stopping implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f97edf1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:07.105619Z",
     "iopub.status.busy": "2024-03-10T12:33:07.104916Z",
     "iopub.status.idle": "2024-03-10T12:33:07.115668Z",
     "shell.execute_reply": "2024-03-10T12:33:07.114023Z"
    },
    "papermill": {
     "duration": 0.026123,
     "end_time": "2024-03-10T12:33:07.119424",
     "exception": false,
     "start_time": "2024-03-10T12:33:07.093301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class TrainingPipeline:\n",
    "#     def __init__(self, device):\n",
    "#         self.device = device\n",
    "\n",
    "#     def train_and_evaluate(self, model, train_loader, val_loader, optimizer, criterion, early_stopping, num_epochs):\n",
    "#         train_losses = []\n",
    "#         val_losses = []\n",
    "#         for epoch in range(num_epochs):\n",
    "#         \"\"\" Train and evaluate the model \"\"\"\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             model (nn.Module): The model to be trained\n",
    "#             train_loader (DataLoader): The training data loader\n",
    "#             val_loader (DataLoader): The validation data loader\n",
    "#             optimizer (Optimizer): The optimizer\n",
    "#             criterion (Loss): The loss function\n",
    "#             early_stopping (EarlyStopping): The early stopping object\n",
    "#             device (torch.device): The device to be used\n",
    "#             num_epochs (int): The number of epochs\n",
    "#         \"\"\"\n",
    "#         train_losses = []\n",
    "#         val_losses = []\n",
    "#         for epoch in range(num_epochs):\n",
    "#             model.train()\n",
    "#             train_loss = 0.0\n",
    "#             for batched_graph, labels in train_loader:\n",
    "#                 batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "#                 optimizer.zero_grad()\n",
    "#                 logits = model(batched_graph, batched_graph.ndata['h'].float())\n",
    "#                 loss = criterion(logits, labels)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 train_loss += loss.item()\n",
    "\n",
    "#             # Validation phase\n",
    "#             model.eval()\n",
    "#             val_loss = 0.0\n",
    "#             with torch.no_grad():\n",
    "#                 for batched_graph, labels in val_loader:\n",
    "#                     batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "#                     logits = model(batched_graph, batched_graph.ndata['h'].float())\n",
    "#                     loss = criterion(logits, labels)\n",
    "#                     val_loss += loss.item()\n",
    "\n",
    "#             train_loss /= len(train_loader)\n",
    "#             val_loss /= len(val_loader)\n",
    "            \n",
    "#             train_losses.append(train_loss)\n",
    "#             val_losses.append(val_loss)\n",
    "            \n",
    "#             early_stopping(val_loss, model)\n",
    "#             if early_stopping.early_stop:\n",
    "#                 print(\"Early stopping triggered at epoch:\", epoch+1)\n",
    "#                 break\n",
    "        \n",
    "#         return train_loss, val_loss, train_losses, val_losses\n",
    "\n",
    "#     def evaluate_on_test(self, model, criterion):\n",
    "#         \"\"\"Evaluate the model on the test set.\"\"\"\n",
    "#         model.eval()\n",
    "#         test_loss = 0.0\n",
    "#         test_accuracy = 0.0\n",
    "#         with torch.no_grad():\n",
    "#             for batched_graph, labels in self.test_loader:\n",
    "#                 batched_graph, labels = batched_graph.to(self.device), labels.to(self.device)\n",
    "#                 logits = model(batched_graph, batched_graph.ndata['h'].float())\n",
    "#                 loss = criterion(logits, labels)\n",
    "#                 test_loss += loss.item()\n",
    "#                 preds = torch.argmax(logits, dim=1)\n",
    "#                 test_accuracy += torch.sum(preds == labels).item()\n",
    "\n",
    "#         test_loss /= len(self.test_loader)\n",
    "#         test_accuracy /= len(self.test_loader.dataset)\n",
    "#         print(\"Test Loss:\", test_loss)\n",
    "#         print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003e1e0",
   "metadata": {
    "papermill": {
     "duration": 0.026449,
     "end_time": "2024-03-10T12:33:07.155004",
     "exception": false,
     "start_time": "2024-03-10T12:33:07.128555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameter Optimization with Optuna\n",
    "Describes the setup for hyperparameter optimization using Optuna, including defining the search space and optimizing the model parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd7da443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:07.508566Z",
     "iopub.status.busy": "2024-03-10T12:33:07.508000Z",
     "iopub.status.idle": "2024-03-10T12:33:07.518769Z",
     "shell.execute_reply": "2024-03-10T12:33:07.516738Z"
    },
    "papermill": {
     "duration": 0.057863,
     "end_time": "2024-03-10T12:33:07.522757",
     "exception": false,
     "start_time": "2024-03-10T12:33:07.464894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class HyperparameterOptimizer:\n",
    "#     def __init__(self, device, train_graphs, train_labels, val_graphs, val_labels, test_graphs, test_labels, num_trials, num_epochs):\n",
    "#         self.device = device\n",
    "#         self.train_graphs = train_graphs\n",
    "#         self.train_labels = train_labels\n",
    "#         self.val_graphs = val_graphs\n",
    "#         self.val_labels = val_labels\n",
    "#         self.test_graphs = test_graphs\n",
    "#         self.test_labels = test_labels\n",
    "#         self.num_trials = num_trials\n",
    "#         self.num_epochs = num_epochs\n",
    "\n",
    "#     def objective(trial):\n",
    "#         \"\"\" Objective function for Optuna \"\"\"\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             trial (optuna.Trial): The trial object\n",
    "#         \"\"\"\n",
    "#         # Suggest hyperparameters\n",
    "#         n_steps = trial.suggest_int('n_steps', 1, 30)\n",
    "#         out_feats = trial.suggest_int('out_feats', 74, 512)\n",
    "#         lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "#         batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512])\n",
    "#         dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "\n",
    "#         # DataLoaders\n",
    "#         train_loader = GraphDataLoader(list(zip(train_graphs, train_labels)), batch_size=batch_size, shuffle=True, collate_fn=collate, num_workers=4)\n",
    "#         val_loader = GraphDataLoader(list(zip(val_graphs, val_labels)), batch_size=batch_size, shuffle=False, collate_fn=collate, num_workers=4)\n",
    "#         test_loader = GraphDataLoader(list(zip(test_graphs, test_labels)), batch_size=batch_size, shuffle=False, collate_fn=collate, num_workers=4)\n",
    "\n",
    "#         # Model initialization\n",
    "#         model = GraphClsGGNN(annotation_size=74, out_feats=out_feats, n_steps=n_steps, n_etypes=1, num_cls=2, dropout_rate=dropout_rate).to(device)\n",
    "#         optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "#         # EarlyStopping instance\n",
    "#         early_stopping = EarlyStopping(patience=7, verbose=False, path='ggnn_checkpoint.pt')\n",
    "\n",
    "#         # Train and evaluate the model\n",
    "#         train_loss, val_loss, train_losses, val_losses = train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, early_stopping, device, num_epochs=num_epochs)\n",
    "\n",
    "#         # Return the negative validation loss to maximize accuracy (minimize loss)\n",
    "#         return -val_loss\n",
    "\n",
    "#     def optimize(self):\n",
    "#         \"\"\"Conduct the hyperparameter optimization.\"\"\"\n",
    "#         study = optuna.create_study(direction='maximize')\n",
    "#         study.optimize(self.objective, n_trials=self.num_trials)\n",
    "\n",
    "#         print(\"Best trial:\")\n",
    "#         trial = study.best_trial\n",
    "#         print(f\"Value: {-trial.value}\")\n",
    "#         print(\"Params: \")\n",
    "#         for key, value in trial.params.items():\n",
    "#             print(f\"{key}: {value}\")\n",
    "        \n",
    "#         # Optionally, visualize the study\n",
    "#         plot_contour(study, params=['lr', 'n_steps', 'out_feats', 'batch_size', 'dropout_rate'])\n",
    "\n",
    "#         # Instantiate the best model for further evaluation\n",
    "#         best_hyperparams = trial.params\n",
    "#         model = GraphClsGGNN(annotation_size=74, \n",
    "#                              out_feats=best_hyperparams['out_feats'], \n",
    "#                              n_steps=best_hyperparams['n_steps'], \n",
    "#                              n_etypes=1, \n",
    "#                              num_cls=2, \n",
    "#                              dropout_rate=best_hyperparams.get('dropout_rate', 0.5)).to(self.device)\n",
    "\n",
    "#         model.load_state_dict(torch.load('ggnn_checkpoint.pt'))\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#         # Evaluate on test set\n",
    "#         training_pipeline = TrainingPipeline(self.device, self.train_loader, self.val_loader, self.test_loader)\n",
    "#         training_pipeline.evaluate_on_test(model, criterion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9aea08",
   "metadata": {
    "papermill": {
     "duration": 0.008069,
     "end_time": "2024-03-10T12:33:07.539146",
     "exception": false,
     "start_time": "2024-03-10T12:33:07.531077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameter Optimization Execution\n",
    "Initiates the hyperparameter optimization process, leveraging the previously defined model, data loaders, and Optuna setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3502f4e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:07.589453Z",
     "iopub.status.busy": "2024-03-10T12:33:07.588924Z",
     "iopub.status.idle": "2024-03-10T12:33:07.596274Z",
     "shell.execute_reply": "2024-03-10T12:33:07.594367Z"
    },
    "papermill": {
     "duration": 0.05376,
     "end_time": "2024-03-10T12:33:07.599291",
     "exception": false,
     "start_time": "2024-03-10T12:33:07.545531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# num_trials = 10\n",
    "# num_epochs = 100\n",
    "\n",
    "# hyperparameter_optimizer = HyperparameterOptimizer(device, train_graphs, train_labels, val_graphs, val_labels, test_graphs, test_labels, num_trials, num_epochs)\n",
    "# hyperparameter_optimizer.optimize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d037ac",
   "metadata": {
    "papermill": {
     "duration": 0.009975,
     "end_time": "2024-03-10T12:33:07.634246",
     "exception": false,
     "start_time": "2024-03-10T12:33:07.624271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6666666666666666666666666666666666666666\n",
    "# Separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcaeae49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:07.667279Z",
     "iopub.status.busy": "2024-03-10T12:33:07.666720Z",
     "iopub.status.idle": "2024-03-10T12:33:10.508465Z",
     "shell.execute_reply": "2024-03-10T12:33:10.506668Z"
    },
    "papermill": {
     "duration": 2.868339,
     "end_time": "2024-03-10T12:33:10.512174",
     "exception": false,
     "start_time": "2024-03-10T12:33:07.643835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2\n",
      "Is CUDA Supported? True\n",
      "1 CUDA device(s) available.\n",
      "CUDA Device Name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dgl\n",
    "from dgl.nn import GatedGraphConv, GlobalAttentionPooling\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from optuna.visualization import plot_contour\n",
    "\n",
    "# Check PyTorch and CUDA availability\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Is CUDA Supported?\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.device_count(), \"CUDA device(s) available.\")\n",
    "    print(\"CUDA Device Name:\", torch.cuda.get_device_name(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692b248",
   "metadata": {
    "papermill": {
     "duration": 0.009166,
     "end_time": "2024-03-10T12:33:10.530936",
     "exception": false,
     "start_time": "2024-03-10T12:33:10.521770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# #######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fbf7b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:10.550380Z",
     "iopub.status.busy": "2024-03-10T12:33:10.549726Z",
     "iopub.status.idle": "2024-03-10T12:33:22.462574Z",
     "shell.execute_reply": "2024-03-10T12:33:22.460943Z"
    },
    "papermill": {
     "duration": 11.92706,
     "end_time": "2024-03-10T12:33:22.466427",
     "exception": false,
     "start_time": "2024-03-10T12:33:10.539367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 47275, Validation: 11819, Test: 14774\n"
     ]
    }
   ],
   "source": [
    "# Load data and prepare for training\n",
    "reloaded_df = pd.read_csv(\"data_mvi/combined_df.csv\")\n",
    "graphs, labels_dict = dgl.load_graphs(\"data_mvi/graphs.bin\")\n",
    "labels = reloaded_df['binds_to_rna'].values\n",
    "\n",
    "# Split dataset train, test\n",
    "train_indices, test_indices, train_labels, test_labels = train_test_split(\n",
    "    range(len(reloaded_df)), labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Split dataset train, validation\n",
    "train_indices, val_indices, train_labels, val_labels = train_test_split(\n",
    "    train_indices, train_labels, test_size=0.2, stratify=train_labels, random_state=42)\n",
    "\n",
    "train_graphs = [graphs[i] for i in train_indices]\n",
    "test_graphs = [graphs[i] for i in test_indices]\n",
    "val_graphs = [graphs[i] for i in val_indices]\n",
    "\n",
    "print(f'Train: {len(train_graphs)}, Validation: {len(val_graphs)}, Test: {len(test_graphs)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "898687ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:22.489315Z",
     "iopub.status.busy": "2024-03-10T12:33:22.488984Z",
     "iopub.status.idle": "2024-03-10T12:33:22.529061Z",
     "shell.execute_reply": "2024-03-10T12:33:22.527357Z"
    },
    "papermill": {
     "duration": 0.055144,
     "end_time": "2024-03-10T12:33:22.532827",
     "exception": false,
     "start_time": "2024-03-10T12:33:22.477683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the GGNN model\n",
    "class GraphClsGGNN(nn.Module):\n",
    "    \"\"\"GGNN for graph classification.\"\"\"\n",
    "    def __init__(self, annotation_size, out_feats, n_steps, n_etypes, num_cls, dropout_rate=0.5):\n",
    "        super(GraphClsGGNN, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.ggnn1 = GatedGraphConv(annotation_size, out_feats, n_steps, n_etypes)\n",
    "        self.ggnn2 = GatedGraphConv(out_feats, out_feats, n_steps, n_etypes)\n",
    "        self.pooling = GlobalAttentionPooling(nn.Linear(out_feats, 1))\n",
    "        self.fc = nn.Linear(out_feats, num_cls)\n",
    "\n",
    "    def forward(self, graph, feat):\n",
    "        h = F.relu(self.ggnn1(graph, feat))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.ggnn2(graph, h))\n",
    "        hg = self.pooling(graph, h)\n",
    "        out = self.fc(hg)\n",
    "        return out\n",
    "\n",
    "# Define the EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=10, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(self.val_loss_min, val_loss))\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "# Define the collate function for the DataLoader\n",
    "def collate(samples):\n",
    "    \"\"\"Collate function for the DataLoader.\"\"\"\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return batched_graph, labels\n",
    "\n",
    "# Define the TrainingPipeline class\n",
    "class TrainingPipeline:\n",
    "    \"\"\"A class to encapsulate the training and evaluation pipeline.\"\"\"\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "\n",
    "    def train_and_evaluate(self, model, train_loader, val_loader, optimizer, criterion, early_stopping, num_epochs):\n",
    "        \"\"\"Train and evaluate the model.\"\"\"\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for batched_graph, labels in train_loader:\n",
    "                batched_graph, labels = batched_graph.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(batched_graph, batched_graph.ndata['h'].float())\n",
    "                loss = criterion(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for batched_graph, labels in val_loader:\n",
    "                    batched_graph, labels = batched_graph.to(self.device), labels.to(self.device)\n",
    "                    logits = model(batched_graph, batched_graph.ndata['h'].float())\n",
    "                    loss = criterion(logits, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "             # Print epoch number and loss every fifth epoch\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print(f'Epoch {epoch + 1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "            \n",
    "            early_stopping(val_loss, model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered at epoch:\", epoch + 1)\n",
    "                break\n",
    "        \n",
    "        return train_losses, val_losses\n",
    "\n",
    "\n",
    "    def evaluate_on_test(self, model, test_loader, criterion):\n",
    "        \"\"\"Evaluate the model on the test set.\"\"\"\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batched_graph, labels in test_loader:\n",
    "                batched_graph, labels = batched_graph.to(self.device), labels.to(self.device)\n",
    "                logits = model(batched_graph, batched_graph.ndata['h'].float())\n",
    "                loss = criterion(logits, labels)\n",
    "                test_loss += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                test_accuracy += torch.sum(preds == labels).item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy /= len(test_loader.dataset)\n",
    "        print(\"Test Loss:\", test_loss)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75530c3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:22.587280Z",
     "iopub.status.busy": "2024-03-10T12:33:22.587020Z",
     "iopub.status.idle": "2024-03-10T12:33:22.598239Z",
     "shell.execute_reply": "2024-03-10T12:33:22.596553Z"
    },
    "papermill": {
     "duration": 0.059562,
     "end_time": "2024-03-10T12:33:22.601721",
     "exception": false,
     "start_time": "2024-03-10T12:33:22.542159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class HyperparameterOptimizer:\n",
    "    def __init__(self, device, train_graphs, train_labels, val_graphs, val_labels, test_graphs, test_labels, num_trials, num_epochs):\n",
    "        self.device = device\n",
    "        self.train_graphs = train_graphs\n",
    "        self.train_labels = train_labels\n",
    "        self.val_graphs = val_graphs\n",
    "        self.val_labels = val_labels\n",
    "        self.test_graphs = test_graphs\n",
    "        self.test_labels = test_labels\n",
    "        self.num_trials = num_trials\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "    def objective(self, trial):\n",
    "        \"\"\"The objective function for the Optuna study.\"\"\"\n",
    "        # Suggest hyperparameters\n",
    "        n_steps = trial.suggest_int('n_steps', 1, 30)\n",
    "        out_feats = trial.suggest_int('out_feats', 74, 512)\n",
    "        lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512])\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "\n",
    "        # DataLoaders\n",
    "        train_loader = GraphDataLoader(list(zip(self.train_graphs, self.train_labels)), batch_size=batch_size, shuffle=True, collate_fn=collate, num_workers=4)\n",
    "        val_loader = GraphDataLoader(list(zip(self.val_graphs, self.val_labels)), batch_size=batch_size, shuffle=False, collate_fn=collate, num_workers=4)\n",
    "        test_loader = GraphDataLoader(list(zip(self.test_graphs, self.test_labels)), batch_size=batch_size, shuffle=False, collate_fn=collate, num_workers=4)\n",
    "\n",
    "        # Model initialization\n",
    "        model = GraphClsGGNN(annotation_size=74, out_feats=out_feats, n_steps=n_steps, n_etypes=1, num_cls=2, dropout_rate=dropout_rate).to(self.device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # EarlyStopping instance\n",
    "        early_stopping = EarlyStopping(patience=5, verbose=False, path='ggnn_checkpoint.pt')\n",
    "\n",
    "        # TrainingPipeline instance for training and evaluation\n",
    "        training_pipeline = TrainingPipeline(self.device)\n",
    "        train_losses, val_losses = training_pipeline.train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, early_stopping, self.num_epochs)\n",
    "\n",
    "        # Return the negative validation loss to maximize accuracy (minimize loss)\n",
    "        return -np.min(val_losses)\n",
    "\n",
    "    def optimize(self):\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(self.objective, n_trials=self.num_trials)\n",
    "        best_hyperparams = study.best_trial.params\n",
    "        with open('best_hyperparameters.json', 'w') as f:\n",
    "            json.dump(best_hyperparams, f)\n",
    "        print(\"Best trial saved to best_hyperparameters.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e64285f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T12:33:22.620348Z",
     "iopub.status.busy": "2024-03-10T12:33:22.620093Z",
     "iopub.status.idle": "2024-03-10T14:52:26.493753Z",
     "shell.execute_reply": "2024-03-10T14:52:26.491884Z"
    },
    "papermill": {
     "duration": 8343.893717,
     "end_time": "2024-03-10T14:52:26.504390",
     "exception": false,
     "start_time": "2024-03-10T12:33:22.610673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 12:33:22,621] A new study created in memory with name: no-name-7f8ba73f-0948-4946-8d0e-f4acd73300b9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 0.4069, Val Loss: 0.4195\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 12:41:05,311] Trial 0 finished with value: -0.35334468588635726 and parameters: {'n_steps': 9, 'out_feats': 269, 'lr': 1.7924926161830276e-05, 'batch_size': 64, 'dropout_rate': 0.095007365974556}. Best is trial 0 with value: -0.35334468588635726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.3582, Val Loss: 0.3533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 0.6673, Val Loss: 0.7435\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 13:06:49,848] Trial 1 finished with value: -0.6062370538711548 and parameters: {'n_steps': 13, 'out_feats': 490, 'lr': 0.03171875471418971, 'batch_size': 256, 'dropout_rate': 0.2439599124744522}. Best is trial 0 with value: -0.35334468588635726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered at epoch: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 0.5085, Val Loss: 0.5041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 14:30:38,532] Trial 2 finished with value: -0.39996357357248347 and parameters: {'n_steps': 30, 'out_feats': 479, 'lr': 0.00010800252804778746, 'batch_size': 256, 'dropout_rate': 0.3877285340390775}. Best is trial 0 with value: -0.35334468588635726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.4098, Val Loss: 0.4158\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 0.3849, Val Loss: 0.3869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 14:41:49,862] Trial 3 finished with value: -0.3350396387038692 and parameters: {'n_steps': 5, 'out_feats': 403, 'lr': 7.39153801001291e-05, 'batch_size': 128, 'dropout_rate': 0.12972280112303025}. Best is trial 3 with value: -0.3350396387038692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.3260, Val Loss: 0.3433\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 0.3802, Val Loss: 0.3707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 14:52:26,484] Trial 4 finished with value: -0.3288701476881633 and parameters: {'n_steps': 4, 'out_feats': 455, 'lr': 4.729846807269786e-05, 'batch_size': 32, 'dropout_rate': 0.23787874753530625}. Best is trial 4 with value: -0.3288701476881633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.3222, Val Loss: 0.3329\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best trial saved to best_hyperparameters.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    num_trials = 5  # Consider adjusting based on computational resources and desired thoroughness\n",
    "    num_epochs = 10  # Adjust based on the dataset size and complexity of the model\n",
    "\n",
    "    # Assume train_graphs, train_labels, val_graphs, val_labels, test_graphs, test_labels are defined\n",
    "    hyperparameter_optimizer = HyperparameterOptimizer(device, train_graphs, train_labels, val_graphs, val_labels, test_graphs, test_labels, num_trials, num_epochs)\n",
    "    hyperparameter_optimizer.optimize()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68e50154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T14:52:26.564018Z",
     "iopub.status.busy": "2024-03-10T14:52:26.563692Z",
     "iopub.status.idle": "2024-03-10T14:52:26.576973Z",
     "shell.execute_reply": "2024-03-10T14:52:26.574994Z"
    },
    "papermill": {
     "duration": 0.029334,
     "end_time": "2024-03-10T14:52:26.580569",
     "exception": false,
     "start_time": "2024-03-10T14:52:26.551235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrain_and_evaluate(device, num_epochs):\n",
    "    print(\"Loading best hyperparameters...\")\n",
    "    with open('best_hyperparameters.json', 'r') as f:\n",
    "        best_hyperparams = json.load(f)\n",
    "\n",
    "    print(\"Initializing data loaders...\")\n",
    "    batch_size = best_hyperparams['batch_size']\n",
    "    train_loader = GraphDataLoader(list(zip(train_graphs, train_labels)), batch_size=batch_size, shuffle=True, collate_fn=collate, num_workers=4)\n",
    "    val_loader = GraphDataLoader(list(zip(val_graphs, val_labels)), batch_size=batch_size, shuffle=False, collate_fn=collate, num_workers=4)\n",
    "    test_loader = GraphDataLoader(list(zip(test_graphs, test_labels)), batch_size=batch_size, shuffle=False, collate_fn=collate, num_workers=4)\n",
    "\n",
    "\n",
    "    print(\"Initializing model with best hyperparameters...\")\n",
    "    model = GraphClsGGNN(annotation_size=74, \n",
    "                         out_feats=best_hyperparams['out_feats'], \n",
    "                         n_steps=best_hyperparams['n_steps'], \n",
    "                         n_etypes=1, \n",
    "                         num_cls=2, \n",
    "                         dropout_rate=best_hyperparams.get('dropout_rate', 0.5)).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_hyperparams['lr'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Starting retraining...\")\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True, delta=0.01, path='retrained_model_checkpoint.pt')\n",
    "    training_pipeline = TrainingPipeline(device)\n",
    "    training_pipeline.train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, early_stopping, num_epochs)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered during retraining.\")\n",
    "\n",
    "    print(\"Evaluating on test set...\")\n",
    "    training_pipeline.evaluate_on_test(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1bb919f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T14:52:26.603995Z",
     "iopub.status.busy": "2024-03-10T14:52:26.603544Z",
     "iopub.status.idle": "2024-03-10T15:11:43.578340Z",
     "shell.execute_reply": "2024-03-10T15:11:43.576439Z"
    },
    "papermill": {
     "duration": 1156.989071,
     "end_time": "2024-03-10T15:11:43.581319",
     "exception": false,
     "start_time": "2024-03-10T14:52:26.592248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best hyperparameters...\n",
      "Initializing data loaders...\n",
      "Initializing model with best hyperparameters...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting retraining...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.466252). Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.466252 --> 0.425908). Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.425908 --> 0.408522). Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.408522 --> 0.382222). Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train Loss: 0.3756, Val Loss: 0.3756\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.382222 --> 0.366717). Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.366717 --> 0.343601). Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Train Loss: 0.3192, Val Loss: 0.3280\n",
      "Validation loss decreased (0.343601 --> 0.327952). Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.327952 --> 0.310104). Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Train Loss: 0.2799, Val Loss: 0.3175\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered at epoch: 18\n",
      "Early stopping triggered during retraining.\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.30774721183947157\n",
      "Test Accuracy: 0.8688236090429132\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # Adjust num_epochs as needed\n",
    "    num_epochs = 50  \n",
    "    retrain_and_evaluate(device, num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9521.596554,
   "end_time": "2024-03-10T15:11:46.643292",
   "environment_variables": {},
   "exception": null,
   "input_path": "gnn_ggnn_optuna_v666_att_weights.ipynb",
   "output_path": "gnn_ggnn_optuna_v666_att_weights.ipynb",
   "parameters": {},
   "start_time": "2024-03-10T12:33:05.046738",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
